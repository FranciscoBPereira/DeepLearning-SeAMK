{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObmqcsy+SPUSdRHZo7T5hs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoBPereira/DeepLearning-SeAMK/blob/main/SeAMK2223_Ex3_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmGqbsINsIlf"
      },
      "outputs": [],
      "source": [
        "#Install Transformers library to run this notebook.\n",
        "\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n"
      ],
      "metadata": {
        "id": "BsBsLZbchzLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 1 - An Introduction to Inference Pipelines**"
      ],
      "metadata": {
        "id": "TMMrWPK-USsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The call to pipeline() specifies the task and the model\n",
        "# The task specification is mandatory. In this case, we are creating a pipeline for sentiment analysis\n",
        "# Model specification is optional. By default, the pipeline selects a particular pretrained model\n",
        "# that has been fine-tuned for sentiment analysis in English: DistilBERT base uncased finetuned SST-2\n",
        "# https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n",
        "\n",
        "MSA1 = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "MSA1(\"I've been waiting for a HuggingFace course my whole life.\")"
      ],
      "metadata": {
        "id": "7bxrhYHFhfit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try  model MSA1 with several other sentences\n",
        "\n",
        "str = ['I hate this so much!', 'Your support team is useless',\n",
        "       'Disliking watercraft is not really my thing.', 'I would really truly love going out in this weather!',\n",
        "       'You should see their decadent dessert menu.',  'I love my mobile but would not recommend it to any of my colleagues.']\n",
        "\n",
        "MSA1(str)"
      ],
      "metadata": {
        "id": "22o4bEqJhwze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change some of the sentences above and check if the analysis is different**"
      ],
      "metadata": {
        "id": "k04ij6SyG0KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can specify another model as a parameter: bertweet-sentiment-analysis\n",
        "# https://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n",
        "\n",
        "\n",
        "MSA2 = pipeline('sentiment-analysis', model='finiteautomata/bertweet-base-sentiment-analysis')"
      ],
      "metadata": {
        "id": "Q4qPYC90llJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY\n",
        "\n",
        "# Apply the new model on the previous sentences and compare performance\n",
        "\n",
        "MSA2(str)\n"
      ],
      "metadata": {
        "id": "iKnqH8HjnZKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot classification task: https://huggingface.co/tasks/zero-shot-classification\n",
        "\n",
        "ZS1 = pipeline('zero-shot-classification')\n",
        "ZS1('This is a course about the Transformers library', candidate_labels=['education', 'politics', 'business'])"
      ],
      "metadata": {
        "id": "TzvHhc_cp-jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which model was selected by default to the Zero-shot classification task?"
      ],
      "metadata": {
        "id": "pMoLqj6gqsPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # TRY\n",
        "\n",
        " # 1. Apply pipeline ZS1 to other sentences / candidate labels\n",
        "\n",
        " # 2. Select another model for this task, create pipeline ZS2 and compare performance\n",
        "\n",
        " ZS2 = pipeline('zero-shot-classification', model='typeform/distilbert-base-uncased-mnli')\n",
        "\n",
        "ZS2('I am travelling to Italy', candidate_labels=['education', 'holidays', 'business'])\n"
      ],
      "metadata": {
        "id": "4vE3h6Rdq3jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Generation task: https://huggingface.co/tasks/text-generation\n",
        "\n",
        "Gen1 = pipeline('text-generation')\n",
        "\n",
        "Gen1('In this course, we will teach you how to',  max_length=100)\n"
      ],
      "metadata": {
        "id": "H2rTFOc7sOFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which model was selected by default to the Text Generation task?"
      ],
      "metadata": {
        "id": "sUopHmIGueJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRY\n",
        "\n",
        " # 1. Apply pipeline Gen1 to generate other sentences\n",
        "\n",
        " # 2. Select another model for this task, create pipeline Gen2 and compare outputs\n",
        "\n",
        "Gen2 = pipeline('text-generation', model = 'distilgpt2')\n",
        "\n",
        "Gen2('In this course, we will teach you how to',  max_length=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "e2TUhEeKumVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation task: https://huggingface.co/tasks/translation\n",
        "\n",
        "# In this task, we explicitly specify the model and address the problem of translating English to Finnish\n",
        "# https://huggingface.co/Helsinki-NLP/opus-mt-en-fi\n",
        "\n",
        "\n",
        "T1 = pipeline('translation', model='Helsinki-NLP/opus-mt-en-fi')\n",
        "\n",
        "T1(['Hugging Face is a great library.', 'Good night.', 'I am traveling to London'])\n"
      ],
      "metadata": {
        "id": "i4Mg59YBMHts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Section 2 - Models**"
      ],
      "metadata": {
        "id": "nSHX615gJLmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a BERT model for Sequence Classification (for a TensorFlow environment)\n",
        "\n",
        "# https://huggingface.co/transformers/v3.0.2/model_doc/bert.html\n",
        "# https://huggingface.co/docs/transformers/model_doc/bert\n",
        "\n",
        "\n",
        "from transformers import TFBertForSequenceClassification\n",
        "\n",
        "modelBERT = TFBertForSequenceClassification.from_pretrained('bert-base-cased')\n"
      ],
      "metadata": {
        "id": "fdpb8bqqJPzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model configuration details\n",
        "\n",
        "modelBERT.config"
      ],
      "metadata": {
        "id": "vGCqPAFlJrJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use this BERT model for sequence classification: https://huggingface.co/tasks/text-classification\n",
        "\n",
        "sequences = ['This dog is cute.', 'I hate you.']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-WluAGZeJ0eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences for BERT\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizerB = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "encoded = tokenizerB(sequences, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "\n",
        "print(encoded)"
      ],
      "metadata": {
        "id": "RGMkdPYFqc_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the model to the encoded sentences and obtain results\n",
        "\n",
        "out = modelBERT(encoded)\n",
        "\n",
        "print(out)\n"
      ],
      "metadata": {
        "id": "uGUwKy2GLnF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "predictions = tf.math.softmax(out.logits, axis=-1)\n",
        "\n",
        "print(np.argmax(predictions.numpy(), axis=1))\n",
        "\n",
        "print('LABELS: ', modelBERT.config.id2label)\n"
      ],
      "metadata": {
        "id": "c9MIIsNRMPQA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}